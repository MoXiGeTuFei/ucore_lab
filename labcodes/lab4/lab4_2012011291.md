#LAB4 实验报告


##【练习1】分配并初始化一个进程控制块（需要编码）
	alloc_proc函数（位于kern/process/proc.c中）负责分配并返回一个新的struct proc_struct结构，用于存储新建立的内核线程的管理信息。
ucore需要对这个结构进行最基本的初始化，你需要完成这个初始化过程。
```
1.实现思路
	需要补全的函数为kern/process/proc.c中的函数alloc_proc。该函数无输入，返回一个线程控制块的指针proc_struct*。
每当线程被创建时,都要用该函数申请一个线程控制块用于管理。比如练习二中用来复制进程的do_fork函数，首先就要申请一个TCB
用于管理。该函数的作用就是分配一个TCB的空间，并进行最初步的初始化。要完成这个函数首先要理解proc_struct（TCB）各成员含义。
然后按照定义赋合理的值就好了。TCB中需要进行此初始化的成员变量的定义如下：
	 *       enum proc_state state;		// 进程的状态，比如ruannable、waiting，由于此时尚未进行具体初始化，所以应该等于PROC_UNINIT。
     *       int pid;                  	// 正常的pid从0开始。这里是粗略初始化，线程并未投入使用，赋为-1。
     *       int runs;                  // 进程跑了几次，赋为0。
     *       uintptr_t kstack;          // 进程的内核栈，在lab5中涉及。这里初始化为0。
     *       volatile bool need_resched;// 是否需要调度，即是否可以主动让出CPU给其他线程。赋为0。
     *       struct proc_struct *parent;// 父进程指针。赋为NULL。
     *       struct mm_struct *mm; 		// 内存管理单元。每个用户进程都有自己的地址空间。
										//	mm成员变量在lab3中用于虚存管理。而内核线程常驻内存，不需要考虑swap page问题。
										//	在lab5中涉及到了用户进程，才考虑进程用户内存空间的swap page问题，mm才会发挥作用。
     *       struct context context;    // 进程上下文。即一堆寄存器的值。赋为0。
     *       struct trapframe *tf;      // trapframe是中断来临时线程保存的一些变量，如寄存器值等。具体解释见下一问。赋为NULL。
     *       uintptr_t cr3;             // 存着页目录表的基址。由于是内核线程，直接用内核空间就行了，所以赋成以前建立好的boot_cr3。
     *       uint32_t flags;           	// 一些标记（尚未知道准确含义）。赋为0。
     *       char name[PROC_NAME_LEN + 1];
	 根据以上解释，就可以进行初始化了。具体代码如下：
// alloc_proc - alloc a proc_struct and init all fields of proc_struct
static struct proc_struct* alloc_proc (void)
{
    struct proc_struct *proc = kmalloc(sizeof(struct proc_struct));
    if (proc != NULL)
    {
    	proc->state=PROC_UNINIT;
    	proc->pid=-1;
    	proc->runs=0;
    	proc->kstack=0;
    	proc->need_resched=0;
    	proc->parent=NULL;
    	proc->mm=NULL;
    	memset(&(proc->context),0,sizeof(proc->context));
    	proc->tf=NULL;
    	proc->cr3=boot_cr3;
    	proc->flags=0;
    	memset((proc->name),0,PROC_NAME_LEN);
    }
    return proc;
}
2.请说明proc_struct中struct context context和struct trapframe *tf成员变量含义和在本实验中的作用是啥？（提示通过看代码和编程调试可以判断出来）
	struct context context:它是进程的上下文，其实就是存储了一堆寄存器的值，用于进程切换。在 uCore中，所有的进程在内核中也是相对独立的，
使用 context 保存寄存器,在内核态中就能够进行进程之间的切换。
	让我来详细分析一下lab4中成员变量context是如何使用的。lab4中，schedule函数用于找到一个可运行的进程，然后调用proc_run()让他跑起来。
这个proc_run()首先完成了页目录表切换、内核栈的切换等工作之后，调用switch_to函数进行上下文切换。在kern/process/switch.S中定义的switch_to函数，
首先将当前的寄存器信息保存至被替换者的context中，又用替换者的context将寄存器替换掉，这样就完成了上下文切换，新的进程就跑起来了。
	 tf：中断帧的指针，总是指向内核栈的某个位置。当进程从用户空间跳到内核空间时，中断帧记录了进程在被中断前的状态。
当内核需要跳回用户空间时，需要调整中断帧以恢复让进程继续执行的各寄存器值。除此之外，为了保证嵌套中断发生时tf总是能够指向当前的trapframe，uCore 在内核栈上维护了 tf 的链。
	在lab4中，kernel_thread函数首先用局部变量tf来保存内核线程的临时中断帧，并把它的指针传递给do_fork函数。然后，
do_fork函数调用copy_thread函数，copy_thread在该进程内核栈上给中断帧分配一块空间，并根据tf指向内容进行初始化。lab4中init_proc的正确执行也涉及到了tf。
从上面context分析，知道了idle_proc -> schedule() -> proc_run() -> switch_to()，此时idle_proc的上下文切换到了init_proc的上下文。继续这条链，当switch_to返回时，
由于context对eip的设置问题，switch_to将返回到forkrets。forkrets函数首先把esp指向当前进程的中断帧，此时执行的是initproc，当执行完最后一条语句iret后，
由于esp指向了current->tf.tf_eip=kernel_thread_entry，就开始在内核中执行kernel_thread_entry函数了（注意这里使用到了中断帧tf）。
而initproc->tf.tf_regs.reg_ebx = init_main，所以在kernl_thread_entry中执行“call %ebx”后，就开始执行initproc的主体了。
```


##【练习2】为新创建的内核线程分配资源（需要编码）
创建一个内核线程需要分配和设置好很多资源。
kernel_thread函数通过调用do_fork函数完成具体内核线程的创建工作。
do_kernel函数会调用alloc_proc函数来分配并初始化一个进程控制块，但alloc_proc只是找到了一小块内存用以记录进程的必要信息，
并没有实际分配这些资源。ucore一般通过do_fork实际创建新的内核线程。
do_fork的作用是，创建当前内核线程的一个副本，它们的执行上下文、代码、数据都一样，但是存储位置不同。
在这个过程中，需要给新内核线程分配资源，并且复制原进程的状态。你需要完成在kern/process/proc.c中的do_fork函数中的处理过程。
```
1.实现思路
	需要补全的函数为kern/process/proc.c中的函数do_fork。大体实现流程如下:
		1. 子进程申请一个TCB
		2. setup_kstack() 子进程申请内核栈
		3. copy_mm() 子进程复制或共享父进程的内存空间
		4. copy_thread() 在TCB中初始化中断帧和上下文
		5. 为子进程申请pid
		6. 同时在两个list中插入子进程
		7. wakup_proc() 让子进程runnable
		8. 返回子进程pid
	需要注意的一点是申请pid、在proc_list、hash_list插入子进程这三个步骤执行的时候要保证不能被打断。举个例子来说，假设在proc_list插入后打断，
则hash_list中还没有该进程。这样假设调度到该进程就会出错。我开始没想到这一点，参考了答案才发现。具体实现如下：

int do_fork(uint32_t clone_flags, uintptr_t stack, struct trapframe *tf) 
{
    int ret = -E_NO_FREE_PROC;
    struct proc_struct *proc;
    if (nr_process >= MAX_PROCESS) {
        goto fork_out;
    }
    ret = -E_NO_MEM;
    proc=alloc_proc();
    if(proc==NULL)  //此处参考了答案。忘记了内存不够的情况。
    {
    	goto fork_out;
    }
    //proc->pid=get_pid(); 写在这个位置有问题。必须关中断。
    if(setup_kstack(proc)!=0)
    {
    	//goto fork_out;
    	goto bad_fork_cleanup_proc;  //参考答案。原来写作了上一行，未清除空间。
    }
    if(copy_mm(clone_flags,proc)!=0)
    {
    	//goto fork_out;
    	goto bad_fork_cleanup_kstack;  //参考答案。原来写作了上一行，未清除空间。
    }
    copy_thread(proc,stack,tf);
    bool intr_flag;
    local_intr_save(intr_flag);    //关中断。看了答案以后才知道。
	proc->pid=get_pid();
    hash_proc(proc);
    list_add(&proc_list,&(proc->list_link));
    nr_process++;
    local_intr_restore(intr_flag);    //开中断。
    wakeup_proc(proc);
    ret=proc->pid;
	fork_out:
		return ret;
	bad_fork_cleanup_kstack:
		put_kstack(proc);
	bad_fork_cleanup_proc:
		kfree(proc);
		goto fork_out;
}

2.请说明ucore是否做到给每个新fork的线程一个唯一的id？请说明你的分析和理由。
答：
	若线程数不超过最大线程数，则可以。见get_pid函数：
1 static int
2 get_pid(void) {
3     static_assert(MAX_PID > MAX_PROCESS);
4     struct proc_struct *proc;
5     list_entry_t *list = &proc_list, *le;
6     static int next_safe = MAX_PID, last_pid = MAX_PID;
7     if (++ last_pid >= MAX_PID) {
8         last_pid = 1;
9         goto inside;
10     }
11     if (last_pid >= next_safe)
12     {
13 		inside:
14 			next_safe = MAX_PID;
15 		repeat:
16 			le = list;
17        while ((le = list_next(le)) != list)
18        {
19            proc = le2proc(le, list_link);
20            if (proc->pid == last_pid)
21            {
22                if (++ last_pid >= next_safe)
23                {
24                    if (last_pid >= MAX_PID)
25                    {
26                        last_pid = 1;
27                    }
28                    next_safe = MAX_PID;
29                    goto repeat;
30                }
31            }
32            else if (proc->pid > last_pid && next_safe > proc->pid)
33            {
34                next_safe = proc->pid;
35            }
36        }
37    }
38    return last_pid;
39 }
分析：
	该函数可以找到最小的一个未被使用的pid，如果存在的话（称之为解）。可以证明，若存在解，该函数保证解存在于[last_pid,nextsafe)中，
这样最后只要返回集合中的最小值last_pid即可。使用数学归纳法证明。证明过程如下：
	（1）开始时last_pid=1,nexsafe=MAX，则[last_pid,nextsafe)=[1,MAX)，解若存在肯定在这个范围。（对应于代码7、8、9行）
	（2）假设解存在于[last_pid,nextsafe)，现在要逐步缩小[last_pid,nextsafe)的范围,并确定last_pid确实为解(last_pid未被使用)。
为此算法遍历了所有proc_list中的pid，对于每一个遍历到的pid，可能有4种情况：
		1、pid<last_pid
		2、pid=last_pid
		3、last_pid<pid<nextsafe
		4、pid>=nextsafe
	对于1、4，由于pid并未落在[last_pid,nextsafe)内，对该集合的缩小并未产生影响。解仍存在于[last_pid,nextsafe)中。(17行开始的while循环进行遍历查找。可以看到对这种情况循环中并未做任何处理)
	对于2，说明此时的last_pid已被使用，不是解，解落在[last_pid+1,nextsafe)中，所以取last_pid=last_pid+1，此时解仍存在于[last_pid,nextsafe)中。（对应于20行）
	对于3，说明解落在[last_pid,pid)或(pid,nextsafe)中。(并且，由于解是可用的最小数，若解存在于后者集合，则等价于前者集合每一个元素都被使用了)
		先假设解存在于前者。则取nextsafe=pid之后，解仍存在于[last_pid,nextsafe)中。(对应于代码34)这样如果算到最后若该集合非空，则说明解确实属于[last_pid,nextsafe)，last_pid确实为最小解（否则遍历中应该出现情况2）。
		若算到最后[last_pid,nextsafe)为空，说明这种情况下（至少某一次）该假设错误，解实际在当初的(pid,nextsafe)中。又因为last_pid(现在的) < nextsafe (现在的) < pid (当初的) ,
		nextsafe<MAX,所以解存在于当初的(pid,nextsafe)，则一定存在于[last_pid,MAX)中。此时取nextsafe=MAX,则解依然在[last_pid,MAX)中。但此时无法保证last_pid就是解，所以不能直接继续遍历，需要重新遍历（对应22行）。
	所以无论如何，循环中，最小解都保证在[last_pid,nextsafe)（若发生情况3的假设错误则会自己调整）。所以最后出while循环，解就是last_pid。
```


##【练习3】阅读代码，理解 proc_run 函数和它调用的函数如何完成进程切换的。（无编码工作）
请在实验报告中简要说明你对proc_run函数的分析。
```
1.请在实验报告中简要说明你对proc_run函数的分析。

	proc_run的代码：
	// proc_run - make process "proc" running on cpu
	// NOTE: before call switch_to, should load  base addr of "proc"'s new PDT
	void
	proc_run(struct proc_struct *proc) {
		if (proc != current) {
			bool intr_flag;
			struct proc_struct *prev = current, *next = proc;
			local_intr_save(intr_flag);
			{
				current = proc;
				load_esp0(next->kstack + KSTACKSIZE);
				lcr3(next->cr3);
				switch_to(&(prev->context), &(next->context));
			}
			local_intr_restore(intr_flag);
		}
	}

	分析：
		进程的调度离不开函数schedule。schedule首先根据调度算法找到一个最优的可跑线程，然后调用proc_run让它“跑”起来。首先，proc_run判断要跑的线程
	是否就是当前线程，若是，什么也不做。然后，proc_run关中断（为避免打扰。具体解释见本练习第三问），并做了如下一些操作：
		1.让current指向next内核线程initproc
		2.设置任务状态段ts中特权态0下的栈顶指针esp0为next内核线程的内核栈的栈顶，即next->kstack + KSTACKSIZE
		3.设置CR3寄存器的值为next内核线程initproc的页目录表起始地址next->cr3，这实际上是完成进程间的页表切换，但在本lab中，两个都是内核线程，都用boot_cr3，没啥好切换的。
		4.调用switch_to函数，完成具体的两个线程的执行现场切换。
		最后将中断使能。
	
2.在本实验的执行过程中，创建且运行了几个内核线程？
	产生2个运行2个。
		产生过程：首先是第1个内核线程idle_proc。它在内核初始化kern_init时由proc_init产生，并放到进程队列。第2个叫init_proc，它是idle_proc创建之后，
	由fork（）函数产生。
		运行过程：在内核做完全部初始化之后调用cpu_idle函数，idle_proc就开始运行了。idle_proc查找到了runnable的init_proc,然后发生进程转换，执行了init_proc。
	转换的具体过程可以见练习一的第2题。

3.语句local_intr_save(intr_flag);....local_intr_restore(intr_flag);在这里有何作用?请说明理由
	local_intr_save(intr_flag)：通过cli使得中断关闭。即不能再处理外界的中断。
	local_intr_restore(intr_flag)：通过sti使得中断打开。
	这两句话联合使用，保证了两句中间的所有操作的原子性，即不能被打断。可以看到，这两句话中间的几个操作需要一气呵成，如果被打断，则会造成严重错误。
两句话之间做了这么几件事：
	1.让current指向next内核线程initproc
	2.设置任务状态段ts中特权态0下的栈顶指针esp0为next内核线程的内核栈的栈顶
	3.设置CR3寄存器,进行页表切换
	4.调用switch_to，进行上下文切换。
	比如，执行完1，突然来了个时钟中断，调用了schedule()，导致又来了个进程切换。则变成了进程切换的嵌套。这是不合理的。需要避免。
```

##【其他】
```
1.说明你的实现与参考答案的区别
答：练习一未参照答案。练习二中写完对比答案发现一些问题，已经以注释形式写在代码中（在上面报告中的练习二部分可以看到）

2.列出你认为本实验中重要的知识点，以及与对应的OS原理中的知识点，并简要说明你对二者的含义，关系，差异等方面的理解。
答：本实验很好的体现了原理课中线程创建、切换这两点，还有TCB中每一项具体代表什么意思。学习原理课时，这些知识还比较笼统，
比如我还并不知道第一个线程init_proc要经过idle_proc -> schedule() -> proc_run() -> switch_to() -> forkret() -> kernel_thread_entry() -> init_main()
这么多函数才能真正跑起来，而且竟然和trapframe有关。我以为只要直接进行上下文切换就好了。做完了lab4，我对内核线程的概念、线程创建、切换的实现细节更加了解了。

```





